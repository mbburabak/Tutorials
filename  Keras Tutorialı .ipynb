{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makine Öğrenimini Kullanarak Otistik Spektrum Bozukluğu Taraması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nörogelişim bozukluklarının erken teşhisi tedaviyi iyileştirebilir ve ilgili sağlık maliyetlerini önemli ölçüde azaltabilir. Bu projede, davranışsal özelliklere ve bireysel özelliklere dayalı Otistik Spektrum Bozukluğunu (ASD) teşhis etmek için denetimli öğrenmeyi kullanacağız. Daha spesifik olarak, Keras'ı kullanarak bir sinir ağı kuracağız ve dağıtacağız.\n",
    "\n",
    "Bu proje, 292 hasta için tarama verilerini içeren UCI Makine Öğrenim Deposu tarafından sağlanan bir veri kümesini kullanacaktır. Veri kümesi aşağıdaki URL'de bulunabilir:\n",
    "https://archive.ics.uci.edu/ml/datasets/Autistic+Spectrum+Disorder+Screening+Data+for+Children++\n",
    "\n",
    "\n",
    "Hemen başlayalım! İlk olarak, bu projede kullanacağımız birkaç kütüphaneyi içe aktaracağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas: 1.0.1\n",
      "Sklearn: 0.22.1\n",
      "Keras: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "\n",
    "print ('Python: {}'.format(sys.version))\n",
    "print ('Pandas: {}'.format(pd.__version__))\n",
    "print ('Sklearn: {}'.format(sklearn.__version__))\n",
    "print ('Keras: {}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Verileri Yükleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Verileri UCI Machine Learning Depository'den alacağız; ancak, veriler bir csv veya txt dosyasında bulunmadığından, sıkıştırılmış zip dosyasını indirip verileri manuel olarak çıkarmamız gerekir. Bu tamamlandıktan sonra, bilgileri Pandalar kullanarak bir metin dosyasından okuyacağız.\n",
    "\n",
    "Dönüştürme için: https://pulipulichen.github.io/HTML5-BayesNet-Tools/arff2csv/ adresini kullanabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri kümesini Yükleme\n",
    "file = 'csv_result-Autism-Child-Data.csv'\n",
    "\n",
    "# Csv Dosyasını Okuma\n",
    "data = pd.read_table(file, sep = ',', index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (292, 22)\n",
      "id                          1\n",
      "A1_Score                    1\n",
      "A2_Score                    1\n",
      "A3_Score                    0\n",
      "A4_Score                    0\n",
      "A5_Score                    1\n",
      "A6_Score                    1\n",
      "A7_Score                    0\n",
      "A8_Score                    1\n",
      "A9_Score                    0\n",
      "A10_Score                   0\n",
      "age                         6\n",
      "gender                      m\n",
      "ethnicity              Others\n",
      "jundice                    no\n",
      "austim                     no\n",
      "contry_of_res          Jordan\n",
      "used_app_before            no\n",
      "result                      5\n",
      "age_desc           4-11 years\n",
      "relation               Parent\n",
      "Class/ASD                  NO\n",
      "Name: 0, dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 292 entries, 0 to 291\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               292 non-null    int64 \n",
      " 1   A1_Score         292 non-null    int64 \n",
      " 2   A2_Score         292 non-null    int64 \n",
      " 3   A3_Score         292 non-null    int64 \n",
      " 4   A4_Score         292 non-null    int64 \n",
      " 5   A5_Score         292 non-null    int64 \n",
      " 6   A6_Score         292 non-null    int64 \n",
      " 7   A7_Score         292 non-null    int64 \n",
      " 8   A8_Score         292 non-null    int64 \n",
      " 9   A9_Score         292 non-null    int64 \n",
      " 10  A10_Score        292 non-null    int64 \n",
      " 11  age              292 non-null    object\n",
      " 12  gender           292 non-null    object\n",
      " 13  ethnicity        292 non-null    object\n",
      " 14  jundice          292 non-null    object\n",
      " 15  austim           292 non-null    object\n",
      " 16  contry_of_res    292 non-null    object\n",
      " 17  used_app_before  292 non-null    object\n",
      " 18  result           292 non-null    int64 \n",
      " 19  age_desc         292 non-null    object\n",
      " 20  relation         292 non-null    object\n",
      " 21  Class/ASD        292 non-null    object\n",
      "dtypes: int64(12), object(10)\n",
      "memory usage: 50.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Veri kümesinin yapısı yazdırma, bu sayede verimiz hakkında bilgi edinebilriiz\n",
    "print ('Shape of DataFrame: {}'.format(data.shape))\n",
    "print (data.loc[0])\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>146.500000</td>\n",
       "      <td>0.633562</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>0.743151</td>\n",
       "      <td>0.551370</td>\n",
       "      <td>0.743151</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.606164</td>\n",
       "      <td>0.496575</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>6.239726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>84.437354</td>\n",
       "      <td>0.482658</td>\n",
       "      <td>0.499682</td>\n",
       "      <td>0.437646</td>\n",
       "      <td>0.498208</td>\n",
       "      <td>0.437646</td>\n",
       "      <td>0.453454</td>\n",
       "      <td>0.489438</td>\n",
       "      <td>0.500847</td>\n",
       "      <td>0.500811</td>\n",
       "      <td>0.446761</td>\n",
       "      <td>2.284882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>73.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>146.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>219.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id    A1_Score    A2_Score    A3_Score    A4_Score    A5_Score  \\\n",
       "count  292.000000  292.000000  292.000000  292.000000  292.000000  292.000000   \n",
       "mean   146.500000    0.633562    0.534247    0.743151    0.551370    0.743151   \n",
       "std     84.437354    0.482658    0.499682    0.437646    0.498208    0.437646   \n",
       "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     73.750000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%    146.500000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "75%    219.250000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max    292.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         A6_Score    A7_Score    A8_Score    A9_Score   A10_Score      result  \n",
       "count  292.000000  292.000000  292.000000  292.000000  292.000000  292.000000  \n",
       "mean     0.712329    0.606164    0.496575    0.493151    0.726027    6.239726  \n",
       "std      0.453454    0.489438    0.500847    0.500811    0.446761    2.284882  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    5.000000  \n",
       "50%      1.000000    1.000000    0.000000    0.000000    1.000000    6.000000  \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    8.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000   10.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veri kümesi hakkında istatistiksel bilgileri yazdırma\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri önişlemesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu veri kümesi için birden fazla önişleme adımı gerekecektir. İlk olarak, veri kümemizde (attributes) sinir ağımızı eğitirken kullanmak istemediğimiz sütunlar var. Önce bu sütunları bırakacağız. İkinci olarak, verilerimizin çoğu dizi(string) kullanılarak rapor edilir; sonuç olarak, verilerimizi kategorik etiketlere dönüştüreceğiz. Önişlemimiz sırasında, veri kümesini X ve Y veri kümelerine böleriz; burada X, tahmin için kullanmak istediğimiz tüm özelliklere ve Y sınıf etiketlerine sahiptir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# İstenmeyen dataları çıkarma\n",
    "data = data.drop(['result', 'age_desc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli eğitmek için verileri gruplara ayırma\n",
    "x = data.drop(['Class/ASD'], 1)\n",
    "y = data['Class/ASD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verileri kategorik değerlere çevirme (one-hot-encoded vectors)\n",
    "X = pd.get_dummies(x)\n",
    "Y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'A1_Score' 'A2_Score' 'A3_Score' 'A4_Score' 'A5_Score' 'A6_Score'\n",
      " 'A7_Score' 'A8_Score' 'A9_Score' 'A10_Score' 'age_10' 'age_11' 'age_4'\n",
      " 'age_5' 'age_6' 'age_7' 'age_8' 'age_9' 'age_?' 'gender_f' 'gender_m'\n",
      " 'ethnicity_?' 'ethnicity_Asian' 'ethnicity_Black' 'ethnicity_Hispanic'\n",
      " 'ethnicity_Latino' 'ethnicity_Middle Eastern ' 'ethnicity_Others'\n",
      " 'ethnicity_Pasifika' 'ethnicity_South Asian' 'ethnicity_Turkish'\n",
      " 'ethnicity_White-European' 'jundice_no' 'jundice_yes' 'austim_no'\n",
      " 'austim_yes' 'contry_of_res_Afghanistan' 'contry_of_res_Argentina'\n",
      " 'contry_of_res_Armenia' 'contry_of_res_Australia' 'contry_of_res_Austria'\n",
      " 'contry_of_res_Bahrain' 'contry_of_res_Bangladesh' 'contry_of_res_Bhutan'\n",
      " 'contry_of_res_Brazil' 'contry_of_res_Bulgaria' 'contry_of_res_Canada'\n",
      " 'contry_of_res_China' 'contry_of_res_Costa Rica' 'contry_of_res_Egypt'\n",
      " 'contry_of_res_Europe' 'contry_of_res_Georgia' 'contry_of_res_Germany'\n",
      " 'contry_of_res_Ghana' 'contry_of_res_India' 'contry_of_res_Iraq'\n",
      " 'contry_of_res_Ireland' 'contry_of_res_Isle of Man' 'contry_of_res_Italy'\n",
      " 'contry_of_res_Japan' 'contry_of_res_Jordan' 'contry_of_res_Kuwait'\n",
      " 'contry_of_res_Latvia' 'contry_of_res_Lebanon' 'contry_of_res_Libya'\n",
      " 'contry_of_res_Malaysia' 'contry_of_res_Malta' 'contry_of_res_Mexico'\n",
      " 'contry_of_res_Nepal' 'contry_of_res_Netherlands'\n",
      " 'contry_of_res_New Zealand' 'contry_of_res_Nigeria' 'contry_of_res_Oman'\n",
      " 'contry_of_res_Pakistan' 'contry_of_res_Philippines'\n",
      " 'contry_of_res_Qatar' 'contry_of_res_Romania' 'contry_of_res_Russia'\n",
      " 'contry_of_res_Saudi Arabia' 'contry_of_res_South Africa'\n",
      " 'contry_of_res_South Korea' 'contry_of_res_Sweden' 'contry_of_res_Syria'\n",
      " 'contry_of_res_Turkey' 'contry_of_res_U.S. Outlying Islands'\n",
      " 'contry_of_res_United Arab Emirates' 'contry_of_res_United Kingdom'\n",
      " 'contry_of_res_United States' 'used_app_before_no' 'used_app_before_yes'\n",
      " 'relation_?' 'relation_Health care professional' 'relation_Parent'\n",
      " 'relation_Relative' 'relation_Self' 'relation_self']\n",
      "['NO' 'YES']\n"
     ]
    }
   ],
   "source": [
    "# Oluşturduğumuz kategorik sütunları inceleyelim\n",
    "print (X.columns.values)\n",
    "print(Y.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Veri Kümesini Eğitim ve Test Veri Kümelerine ayırın"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinir ağımızı eğitmeye başlamadan önce, veri kümesini eğitim ve test veri kümelerine ayırmamız gerekir. Bu, eğitim bittikten sonra yeni verilere ne kadar genelleştirileceğini belirlemek için ağımızı test etmemizi sağlayacaktır. Scikit-learn tarafından sağlanan train_test_split () işlevini kullanırken bu adım inanılmaz derecede kolay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Oluşturduğumuz veri gruplarını(X,Y) eğitim ve test aşaması için bölme\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233, 97)\n",
      "(59, 97)\n",
      "(233, 2)\n",
      "(59, 2)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (Y_train.shape)\n",
    "print (Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sinir ağı kurma - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu projede, ağımızı kurmak ve eğitmek için Keras'ı kullanacağız. Bu model nispeten basit olacak ve sadece yoğun (Dense) katmanları kullanacaktır. Bu en yaygın sinir ağı katmanıdır. Ağın bir gizli katmanı olacak, bir Adam optimize edici ve kategorik bir çapraz-girişim kaybı(categorical crossentropy loss) olacak. Öğrenme hızı, her katmandaki nöron sayısı veya bu projedeki aktivasyon fonksiyonları gibi parametreleri optimize etmekle zaman kaybetmeyeceğiz; Bununla birlikte, zamanınız varsa, bu parametreleri manuel olarak ayarlamak ve sonuçları gözlemlemek, işlevleri hakkında bilgi edinmek için harika bir yoldur!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 8)                 784       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 830\n",
      "Trainable params: 830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Sinir ağını kurmak - Keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Keras modelini kurmak için fonksiyon oluşturma\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=97, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    # Model Derlemesi(compile)\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sinir ağını eğitme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi eğlence zamanı :)\n",
    "Bir Keras modelini eğitmek, model.fit () işlevini çağırmak kadar basittir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "233/233 [==============================] - 0s 509us/step - loss: 0.7012 - accuracy: 0.4635\n",
      "Epoch 2/50\n",
      "233/233 [==============================] - 0s 94us/step - loss: 0.6929 - accuracy: 0.5279\n",
      "Epoch 3/50\n",
      "233/233 [==============================] - 0s 94us/step - loss: 0.6921 - accuracy: 0.5279\n",
      "Epoch 4/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.6896 - accuracy: 0.5279\n",
      "Epoch 5/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.6886 - accuracy: 0.5279\n",
      "Epoch 6/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.6859 - accuracy: 0.5451\n",
      "Epoch 7/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.6823 - accuracy: 0.5622\n",
      "Epoch 8/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.6776 - accuracy: 0.5923\n",
      "Epoch 9/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.6718 - accuracy: 0.7382\n",
      "Epoch 10/50\n",
      "233/233 [==============================] - 0s 111us/step - loss: 0.6610 - accuracy: 0.6309\n",
      "Epoch 11/50\n",
      "233/233 [==============================] - 0s 94us/step - loss: 0.6487 - accuracy: 0.6567\n",
      "Epoch 12/50\n",
      "233/233 [==============================] - 0s 94us/step - loss: 0.6362 - accuracy: 0.6953\n",
      "Epoch 13/50\n",
      "233/233 [==============================] - 0s 94us/step - loss: 0.6312 - accuracy: 0.7940\n",
      "Epoch 14/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.5996 - accuracy: 0.7597\n",
      "Epoch 15/50\n",
      "233/233 [==============================] - 0s 107us/step - loss: 0.5835 - accuracy: 0.7940\n",
      "Epoch 16/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.5606 - accuracy: 0.8240\n",
      "Epoch 17/50\n",
      "233/233 [==============================] - 0s 94us/step - loss: 0.5585 - accuracy: 0.8026\n",
      "Epoch 18/50\n",
      "233/233 [==============================] - 0s 94us/step - loss: 0.5248 - accuracy: 0.8412\n",
      "Epoch 19/50\n",
      "233/233 [==============================] - 0s 107us/step - loss: 0.5063 - accuracy: 0.8240\n",
      "Epoch 20/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.4774 - accuracy: 0.8755\n",
      "Epoch 21/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.4730 - accuracy: 0.8455\n",
      "Epoch 22/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.4459 - accuracy: 0.8755\n",
      "Epoch 23/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.4243 - accuracy: 0.8584\n",
      "Epoch 24/50\n",
      "233/233 [==============================] - 0s 94us/step - loss: 0.3926 - accuracy: 0.8798\n",
      "Epoch 25/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.3929 - accuracy: 0.8927\n",
      "Epoch 26/50\n",
      "233/233 [==============================] - 0s 107us/step - loss: 0.3607 - accuracy: 0.8841\n",
      "Epoch 27/50\n",
      "233/233 [==============================] - 0s 120us/step - loss: 0.3385 - accuracy: 0.9270\n",
      "Epoch 28/50\n",
      "233/233 [==============================] - 0s 111us/step - loss: 0.3234 - accuracy: 0.9013\n",
      "Epoch 29/50\n",
      "233/233 [==============================] - 0s 116us/step - loss: 0.3032 - accuracy: 0.9056\n",
      "Epoch 30/50\n",
      "233/233 [==============================] - 0s 137us/step - loss: 0.2866 - accuracy: 0.9185\n",
      "Epoch 31/50\n",
      "233/233 [==============================] - 0s 116us/step - loss: 0.2874 - accuracy: 0.9056\n",
      "Epoch 32/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.2667 - accuracy: 0.9270\n",
      "Epoch 33/50\n",
      "233/233 [==============================] - 0s 94us/step - loss: 0.2769 - accuracy: 0.8841\n",
      "Epoch 34/50\n",
      "233/233 [==============================] - 0s 107us/step - loss: 0.2295 - accuracy: 0.9399\n",
      "Epoch 35/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.2101 - accuracy: 0.9485\n",
      "Epoch 36/50\n",
      "233/233 [==============================] - 0s 107us/step - loss: 0.1973 - accuracy: 0.9571\n",
      "Epoch 37/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.1830 - accuracy: 0.9700\n",
      "Epoch 38/50\n",
      "233/233 [==============================] - 0s 107us/step - loss: 0.1806 - accuracy: 0.9571\n",
      "Epoch 39/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.1701 - accuracy: 0.9614\n",
      "Epoch 40/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.1553 - accuracy: 0.9700\n",
      "Epoch 41/50\n",
      "233/233 [==============================] - 0s 107us/step - loss: 0.1487 - accuracy: 0.9785\n",
      "Epoch 42/50\n",
      "233/233 [==============================] - 0s 107us/step - loss: 0.1506 - accuracy: 0.9528\n",
      "Epoch 43/50\n",
      "233/233 [==============================] - 0s 107us/step - loss: 0.1322 - accuracy: 0.9700\n",
      "Epoch 44/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.1236 - accuracy: 0.9785\n",
      "Epoch 45/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.1093 - accuracy: 0.9914\n",
      "Epoch 46/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.1127 - accuracy: 0.9785\n",
      "Epoch 47/50\n",
      "233/233 [==============================] - 0s 103us/step - loss: 0.1488 - accuracy: 0.9571\n",
      "Epoch 48/50\n",
      "233/233 [==============================] - 0s 98us/step - loss: 0.1903 - accuracy: 0.9099\n",
      "Epoch 49/50\n",
      "233/233 [==============================] - 0s 111us/step - loss: 0.1014 - accuracy: 0.9742\n",
      "Epoch 50/50\n",
      "233/233 [==============================] - 0s 111us/step - loss: 0.0891 - accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x250892d9608>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeli eğitim veri kümelerimizle eğitme\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modeli Test Etme ve Performans Metrikleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelimiz eğitildiğine göre, performansını test veri kümesinde test etmemiz gerekiyor. Model bu bilgiyi daha önce hiç görmedi; sonuç olarak, test veri seti, modelin eğitim aşamasında kullanılmayan bilgilere genelleme yapıp yapamayacağını belirlememizi sağlar. Bu amaçla scikit-learn tarafından sağlanan metriklerden bazılarını kullanacağız!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kategorik model için tahminler kullanarak sınıflandırma raporu oluşturabilir\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "predictions = model.predict_classes(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Categorical Model\n",
      "0.864406779661017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86        28\n",
      "           1       0.90      0.84      0.87        31\n",
      "\n",
      "    accuracy                           0.86        59\n",
      "   macro avg       0.86      0.87      0.86        59\n",
      "weighted avg       0.87      0.86      0.86        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Results for Categorical Model')\n",
    "print(accuracy_score(Y_test[['YES']], predictions))\n",
    "print(classification_report(Y_test[['YES']], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
